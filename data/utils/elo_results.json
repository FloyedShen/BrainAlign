{
    "Qwen_Qwen2.5-72B-Instruct": 1257.1846949224478,
    "meta-llama_Llama-3.3-70B-Instruct": 1255.2194348825979,
    "meta-llama_Llama-3.1-70B-Instruct": 1247.7839342138718,
    "mistralai_Mistral-Large-Instruct-2411": 1246.5166545495322,
    "allenai_Llama-3.1-Tulu-3-70B": 1243.663380856347,
    "princeton-nlp_gemma-2-9b-it-SimPO": 1215.866597513047,
    "google_gemma-2-9b-it": 1191.796054258954,
    "allenai_Llama-3.1-Tulu-3-8B": 1184.9219168053514,
    "mistralai_Ministral-8B-Instruct-2410": 1181.9817028876078,
    "meta-llama_Llama-3.1-8B-Instruct": 1175.7070289525227,
    "internlm_internlm2_5-20b-chat": 1149.0597723034957,
    "Qwen_Qwen1.5-72B-Chat": 1147.480350514119,
    "google_gemma-2-2b-it": 1143.1007927992903,
    "Qwen_Qwen1.5-32B-Chat": 1125.439955208045,
    "microsoft_Phi-3-medium-4k-instruct": 1123.0886144944284,
    "Qwen_Qwen1.5-14B-Chat": 1108.8885133006515,
    "meta-llama_Llama-3.2-3B-Instruct": 1102.9031363386334,
    "google_gemma-1.1-7b-it": 1083.7715565707067,
    "mistralai_Mistral-7B-Instruct-v0.2": 1072.206086946871,
    "Qwen_Qwen1.5-7B-Chat": 1069.9023748966938,
    "microsoft_Phi-3-mini-4k-instruct": 1066.2297266758414,
    "meta-llama_Llama-3.2-1B-Instruct": 1053.8531551662459,
    "google_gemma-7b-it": 1037.5350930413397,
    "google_gemma-1.1-2b-it": 1020.9170439440574,
    "google_gemma-2b-it": 989.4020382863237,
    "Qwen_Qwen1.5-4B-Chat": 988.3832803429324,
    "google_gemma-2-27b-it": 1220,
    "mistralai_Mistral-Small-Instruct-2409": 1211,
    "Qwen_Qwen2-72B-Instruct": 1187.1973694872554,
    "mistralai_Mistral-Nemo-Instruct-2407": 1251.5597926711748
}

